{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript-Conditioned LLM Reasoning Demo\n",
    "\n",
    "This notebook demonstrates that a language model does not internally commit to a secret in a 20-questions game. Instead, it reconstructs the secret from the visible transcript.\n",
    "\n",
    "**Method:** We define a small secret space of animals, generate a unique Q&A transcript for each secret, and show that the same model instance declares a different secret depending solely on the transcript it sees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Secret Space Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECRETS = {\n",
    "    \"cat\": {\n",
    "        \"mammal\": True,\n",
    "        \"flies\": False,\n",
    "        \"swims\": False,\n",
    "        \"has_fur\": True,\n",
    "        \"fish\": False,\n",
    "        \"predator\": True,\n",
    "        \"pet\": True,\n",
    "        \"barks\": False,\n",
    "    },\n",
    "    \"dog\": {\n",
    "        \"mammal\": True,\n",
    "        \"flies\": False,\n",
    "        \"swims\": False,\n",
    "        \"has_fur\": True,\n",
    "        \"fish\": False,\n",
    "        \"predator\": True,\n",
    "        \"pet\": True,\n",
    "        \"barks\": True,\n",
    "    },\n",
    "    \"eagle\": {\n",
    "        \"mammal\": False,\n",
    "        \"flies\": True,\n",
    "        \"swims\": False,\n",
    "        \"has_fur\": False,\n",
    "        \"fish\": False,\n",
    "        \"predator\": True,\n",
    "        \"pet\": False,\n",
    "        \"barks\": False,\n",
    "    },\n",
    "    \"salmon\": {\n",
    "        \"mammal\": False,\n",
    "        \"flies\": False,\n",
    "        \"swims\": True,\n",
    "        \"has_fur\": False,\n",
    "        \"fish\": True,\n",
    "        \"predator\": False,\n",
    "        \"pet\": False,\n",
    "        \"barks\": False,\n",
    "    },\n",
    "    \"shark\": {\n",
    "        \"mammal\": False,\n",
    "        \"flies\": False,\n",
    "        \"swims\": True,\n",
    "        \"has_fur\": False,\n",
    "        \"fish\": True,\n",
    "        \"predator\": True,\n",
    "        \"pet\": False,\n",
    "        \"barks\": False,\n",
    "    },\n",
    "    \"crocodile\": {\n",
    "        \"mammal\": False,\n",
    "        \"flies\": False,\n",
    "        \"swims\": True,\n",
    "        \"has_fur\": False,\n",
    "        \"fish\": False,\n",
    "        \"predator\": True,\n",
    "        \"pet\": False,\n",
    "        \"barks\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Verify all secrets have the same feature keys\n",
    "feature_keys = list(next(iter(SECRETS.values())).keys())\n",
    "assert all(list(v.keys()) == feature_keys for v in SECRETS.values()), \"Feature keys mismatch\"\n",
    "\n",
    "# Verify all secrets are unique\n",
    "vectors = [tuple(v.values()) for v in SECRETS.values()]\n",
    "assert len(vectors) == len(set(vectors)), \"Duplicate feature vectors found\"\n",
    "\n",
    "print(f\"Defined {len(SECRETS)} secrets with {len(feature_keys)} features each.\")\n",
    "print(f\"Features: {feature_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Question Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTIONS = {\n",
    "    \"mammal\": \"Is it a mammal?\",\n",
    "    \"flies\": \"Does it fly?\",\n",
    "    \"swims\": \"Does it swim?\",\n",
    "    \"has_fur\": \"Does it have fur?\",\n",
    "    \"fish\": \"Is it a fish?\",\n",
    "    \"predator\": \"Is it a predator?\",\n",
    "    \"pet\": \"Is it commonly kept as a pet?\",\n",
    "    \"barks\": \"Does it bark?\",\n",
    "}\n",
    "\n",
    "# Verify 1-to-1 mapping with feature keys\n",
    "assert set(QUESTIONS.keys()) == set(feature_keys), \"Questions don't match features\"\n",
    "print(\"Question templates defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transcript Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transcript(secret_name: str) -> str:\n",
    "    \"\"\"Build a Q&A transcript for the given secret using fixed question order.\"\"\"\n",
    "    features = SECRETS[secret_name]\n",
    "    lines = []\n",
    "    for feature in feature_keys:\n",
    "        question = QUESTIONS[feature]\n",
    "        answer = \"Yes.\" if features[feature] else \"No.\"\n",
    "        lines.append(f\"User: {question}\")\n",
    "        lines.append(f\"Assistant: {answer}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# Preview one transcript\n",
    "print(\"=== Transcript for 'eagle' ===\")\n",
    "print(build_transcript(\"eagle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECRET_LIST = list(SECRETS.keys())\n",
    "\n",
    "\n",
    "def build_prompt(secret_list: list[str], transcript: str) -> str:\n",
    "    \"\"\"Wrap transcript into a prompt for the model.\"\"\"\n",
    "    secrets_str = \", \".join(secret_list)\n",
    "    return (\n",
    "        f\"You are playing 20 questions. You have secretly chosen one of the following: \"\n",
    "        f\"{secrets_str}.\\n\"\n",
    "        f\"Here is the conversation so far:\\n\\n\"\n",
    "        f\"{transcript}\\n\\n\"\n",
    "        f\"User: I give up. What was the secret?\\n\"\n",
    "        f\"Assistant:\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Preview\n",
    "print(build_prompt(SECRET_LIST, build_transcript(\"shark\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feasibility Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feasible_set(transcript: str) -> list[str]:\n",
    "    \"\"\"Parse transcript answers and return secrets consistent with them.\"\"\"\n",
    "    # Parse answers from transcript\n",
    "    observed = {}\n",
    "    lines = transcript.strip().split(\"\\n\")\n",
    "    i = 0\n",
    "    while i < len(lines) - 1:\n",
    "        user_line = lines[i].strip()\n",
    "        assistant_line = lines[i + 1].strip()\n",
    "        if user_line.startswith(\"User:\") and assistant_line.startswith(\"Assistant:\"):\n",
    "            question_text = user_line[len(\"User:\"):].strip()\n",
    "            answer_text = assistant_line[len(\"Assistant:\"):].strip().lower()\n",
    "            # Find which feature this question maps to\n",
    "            for feature, q in QUESTIONS.items():\n",
    "                if q == question_text:\n",
    "                    observed[feature] = answer_text.startswith(\"yes\")\n",
    "                    break\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Filter secrets\n",
    "    feasible = []\n",
    "    for name, features in SECRETS.items():\n",
    "        match = True\n",
    "        for feature, value in observed.items():\n",
    "            if features.get(feature) != value:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            feasible.append(name)\n",
    "    return feasible\n",
    "\n",
    "\n",
    "# Verify every secret's transcript uniquely identifies it\n",
    "for name in SECRETS:\n",
    "    t = build_transcript(name)\n",
    "    fs = compute_feasible_set(t)\n",
    "    assert fs == [name], f\"Expected [{name}], got {fs}\"\n",
    "    print(f\"{name}: feasible set = {fs}  ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "print(f\"Loading tokenizer from {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"Loading model from {MODEL_NAME}...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on: {model.device if hasattr(model, 'device') else 'multiple devices (device_map=auto)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(transcript: str) -> str:\n",
    "    \"\"\"Run inference on a transcript and return the model's predicted secret.\"\"\"\n",
    "    prompt = build_prompt(SECRET_LIST, transcript)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Decode only the newly generated tokens\n",
    "    generated = tokenizer.decode(output[0][input_len:], skip_special_tokens=True).strip()\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all transcripts\n",
    "transcripts = {name: build_transcript(name) for name in SECRETS}\n",
    "\n",
    "# Run experiments\n",
    "results = {}\n",
    "for name, transcript in transcripts.items():\n",
    "    prediction = run_experiment(transcript)\n",
    "    feasible = compute_feasible_set(transcript)\n",
    "    results[name] = prediction\n",
    "\n",
    "    print(f\"Transcript implied: {name}\")\n",
    "    print(f\"Feasible set size: {len(feasible)}\")\n",
    "    print(f\"Feasible set: {feasible}\")\n",
    "    print(f\"Model said: {prediction}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Contradictory Case\n",
    "\n",
    "This transcript is logically impossible — no secret matches all answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contradictory_transcript = \"\"\"User: Is it a mammal?\n",
    "Assistant: Yes.\n",
    "User: Is it a fish?\n",
    "Assistant: Yes.\n",
    "User: Does it fly?\n",
    "Assistant: Yes.\"\"\"\n",
    "\n",
    "feasible = compute_feasible_set(contradictory_transcript)\n",
    "print(f\"Feasible set size: {len(feasible)}\")\n",
    "print(f\"Feasible set: {feasible}\")\n",
    "print()\n",
    "\n",
    "contradictory_result = run_experiment(contradictory_transcript)\n",
    "print(f\"Contradictory transcript result:\")\n",
    "print(f\"Model said: {contradictory_result}\")\n",
    "print(\"-\" * 40)\n",
    "print()\n",
    "print(\"The model produced an answer despite no valid secret existing.\")\n",
    "print(\"This confirms the model reconstructs state from the transcript\")\n",
    "print(\"rather than maintaining a committed hidden state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "\n",
    "# Check if different transcripts produced different outputs\n",
    "unique_outputs = set(results.values())\n",
    "print(f\"Unique model outputs: {len(unique_outputs)} (from {len(results)} transcripts)\")\n",
    "print()\n",
    "\n",
    "for name, prediction in results.items():\n",
    "    match_marker = \"\" if name.lower() in prediction.lower() else \"  <-- MISMATCH\"\n",
    "    print(f\"  {name:>12s} -> {prediction}{match_marker}\")\n",
    "\n",
    "print()\n",
    "print(f\"Contradictory -> {contradictory_result}\")\n",
    "print()\n",
    "print(\"If most consistent transcripts yielded the correct secret,\")\n",
    "print(\"the model is reconstructing state from the transcript.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
